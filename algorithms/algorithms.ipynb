{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "# import linear regression from sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg = LinearRegression()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(df[x-variables],dfp[y-variable], test_size=0.2)\n",
    "\n",
    "# training a linear regression model on training data\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "# predicting on cv\n",
    "pred_cv = lreg.predict(x_cv)\n",
    "\n",
    "# calculating mse\n",
    "mse = np.mean((pred_cv-y_cv)**2)\n",
    "\n",
    "# evaluation using R-Square\n",
    "lreg.score(x_cv,y_cv)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(df[x-variables],dfp[y-variable], test_size=0.2)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "#coefficient and intercept\n",
    "model.coef_\n",
    "model.intercept_\n",
    "\n",
    "#predict the output\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Decision Trees\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables],df[y-variable], test_size=0.2)\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini') # for classification, the parameter 'criterion' can be either 'gini' or 'entropy'. By default it is 'gini')\n",
    "\n",
    "model = tree.DecisionTreeRegressor() # for regression problems\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "model = svm.svc()\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "model = GaussianNB() # for multinomial class use 'BernoulliNB()'\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3) # default value of n_neighbors = 5\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# K-Means Clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Dimensionality reduction algorithms\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "pca = decomposition.PCA(n_components=k) # default value of k = min(n_samples, n_features)\n",
    "\n",
    "# Factor Analysis\n",
    "fa = decomposition.FactorAnalysis()\n",
    "\n",
    "# Reducing the dimension of Training dataset using PCA\n",
    "train_reduced = pca.fit_transform(x_train)\n",
    "\n",
    "# Reducing the dimension of Test dataset using PCA\n",
    "test_reduced = pca.fit_transform(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[x-variables], df[y-variable], test_size=0.2)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "# Training the model and checking the score\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_train,y_train)\n",
    "\n",
    "# Predict output\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------"
   ]
  }
 ]
}